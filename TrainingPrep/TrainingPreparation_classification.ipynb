{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime, timedelta, date\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import Training_function as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:\\\\庫存健診開發\\\\data\\\\Training\\\\Raw\\\\Cluster_7.csv', converters={'ts': str, 'StockNo': str, 'StockName': str})\n",
    "data['ts'] = pd.to_datetime(data['ts'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [group[1] for group in data.groupby(data['StockNo'])]\n",
    "train_list, test_list = [], []\n",
    "\n",
    "train_list, val_list, test_list = [], [], []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(processes=12) as pool:\n",
    "        for j, x in enumerate(tqdm(pool.imap_unordered(partial(func.TrainTestSplit, TrainDate=date(2017,1,1), ValDate=date(2017,9,1)), df_list), total=len(df_list)), 1):\n",
    "            train_list.append(x[0])\n",
    "            val_list.append(x[1])\n",
    "            test_list.append(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [train_list, val_list, test_list]\n",
    "\n",
    "X_train, Y_train, Y_train_ATR, X_val, Y_val, Y_val_ATR, X_test, Y_test, Y_test_ATR = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(processes=12) as pool:\n",
    "        for i, stockdata in enumerate(df_list):\n",
    "            if i == 0:\n",
    "                for j, x in enumerate(tqdm(pool.imap_unordered(partial(func.create_dataset_classification, lookback=20, forward=1), stockdata), total=len(stockdata)), 1):\n",
    "                    for xx in x[0]:\n",
    "                        X_train.append(xx.tolist())\n",
    "                    Y_train.extend(x[1])\n",
    "                    Y_train_ATR.extend(x[2])\n",
    "            elif i == 1:\n",
    "                for j, x in enumerate(tqdm(pool.imap_unordered(partial(func.create_dataset_classification, lookback=20, forward=1), stockdata), total=len(stockdata)), 1):\n",
    "                    for xx in x[0]:\n",
    "                        X_val.append(xx.tolist())\n",
    "                    Y_val.extend(x[1])\n",
    "                    Y_val_ATR.extend(x[2])\n",
    "            else:\n",
    "                for j, x in enumerate(tqdm(pool.imap_unordered(partial(func.create_dataset_classification, lookback=20, forward=1), stockdata), total=len(stockdata)), 1):\n",
    "                    for xx in x[0]:\n",
    "                        X_test.append(xx.tolist())\n",
    "                    Y_test.extend(x[1])\n",
    "                    Y_test_ATR.extend(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(len(X_train) == len(Y_train) == len(Y_train_ATR)) and (len(X_val) == len(Y_val) == len(Y_val_ATR)) and (len(X_test) == len(Y_test) == len(Y_test_ATR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train, Y_train_ATR, Y_val, Y_val_ATR, Y_test, Y_test_ATR = func.categorical_transform(Y_train),  func.categorical_transform(Y_train_ATR), func.categorical_transform(Y_val), func.categorical_transform(Y_val_ATR), func.categorical_transform(Y_test), func.categorical_transform(Y_test_ATR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_list = [X_train, Y_train, Y_train_ATR, X_val, Y_val, Y_val_ATR, X_test, Y_test, Y_test_ATR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 7\n",
    "import pickle\n",
    "with open(f'D:\\\\庫存健診開發\\\\data\\\\Training\\\\processed\\\\Cluster_{cluster}_classification_minmax0_Daily', 'wb') as fp:\n",
    "    pickle.dump(save_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_ATR.count('flat')/len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
