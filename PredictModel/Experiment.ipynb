{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\011553\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# tqdm.pandas()\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, TimeDistributed, LeakyReLU, Conv1D, BatchNormalization, MaxPooling1D, AveragePooling1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "\n",
    "from Model_class import CNN_model, CNN_Tree_Classifier, CNN_Bagging, CNN_Boosting\n",
    "\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = 0\n",
    "with open(f'D:\\\\庫存健診開發\\\\data\\\\Training\\\\processed\\\\Cluster_{cluster}_classification_minmax0_Weekly', 'rb') as fp:\n",
    "    load_list = pickle.load(fp)\n",
    "len(load_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'Conv_layer': 3,\n",
    "                        'Dense_layer': 1,\n",
    "                        'Dense': [128],\n",
    "                        'dropout_ratio': [0.2, 0.2, 0.2],\n",
    "                        'filter': [64, 128, 128],\n",
    "                        'kernel': [3, 3, 3],\n",
    "                        'padding': ['causal', 'causal', 'causal'],\n",
    "                        'learning_rate': 0.001,\n",
    "                        'batch': 256,\n",
    "                        'epochs': 10}\n",
    "\n",
    "Param={'n_estimator': 3,\n",
    "        'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = CNN_Boosting(load_list, Param=Param, CNNparam=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\011553\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\011553\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\011553\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0268718f2ce49a9a3e6110629106257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1021 15:02:58.123765  2864 deprecation.py:506] From C:\\Users\\011553\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 157653 samples, validate on 27592 samples\n",
      "Epoch 1/10\n",
      "157653/157653 - 5s - loss: 0.6768 - acc: 0.5784 - val_loss: 0.6749 - val_acc: 0.5820\n",
      "Epoch 2/10\n",
      "157653/157653 - 3s - loss: 0.6691 - acc: 0.5945 - val_loss: 0.6706 - val_acc: 0.5886\n",
      "Epoch 3/10\n",
      "157653/157653 - 3s - loss: 0.6668 - acc: 0.5989 - val_loss: 0.6716 - val_acc: 0.5861\n",
      "Epoch 4/10\n",
      "157653/157653 - 3s - loss: 0.6654 - acc: 0.6003 - val_loss: 0.6702 - val_acc: 0.5918\n",
      "Epoch 5/10\n",
      "157653/157653 - 3s - loss: 0.6644 - acc: 0.6022 - val_loss: 0.6698 - val_acc: 0.5879\n",
      "Epoch 6/10\n",
      "157653/157653 - 3s - loss: 0.6639 - acc: 0.6027 - val_loss: 0.6703 - val_acc: 0.5893\n",
      "Epoch 7/10\n",
      "157653/157653 - 3s - loss: 0.6632 - acc: 0.6035 - val_loss: 0.6702 - val_acc: 0.5869\n",
      "Epoch 8/10\n",
      "157653/157653 - 3s - loss: 0.6627 - acc: 0.6051 - val_loss: 0.6707 - val_acc: 0.5914\n",
      "Epoch 9/10\n",
      "157653/157653 - 3s - loss: 0.6622 - acc: 0.6056 - val_loss: 0.6695 - val_acc: 0.5896\n",
      "Epoch 10/10\n",
      "157653/157653 - 3s - loss: 0.6617 - acc: 0.6059 - val_loss: 0.6713 - val_acc: 0.5898\n",
      "197067/197067 [==============================] - ETA: 2s - loss: 0.6641 - acc: 0.600 - ETA: 1s - loss: 0.6618 - acc: 0.607 - ETA: 1s - loss: 0.6593 - acc: 0.607 - ETA: 0s - loss: 0.6576 - acc: 0.610 - ETA: 0s - loss: 0.6585 - acc: 0.608 - ETA: 0s - loss: 0.6586 - acc: 0.606 - ETA: 0s - loss: 0.6581 - acc: 0.608 - ETA: 0s - loss: 0.6579 - acc: 0.608 - ETA: 0s - loss: 0.6584 - acc: 0.608 - ETA: 0s - loss: 0.6582 - acc: 0.608 - ETA: 0s - loss: 0.6587 - acc: 0.608 - ETA: 0s - loss: 0.6594 - acc: 0.607 - ETA: 0s - loss: 0.6594 - acc: 0.607 - ETA: 0s - loss: 0.6594 - acc: 0.607 - ETA: 0s - loss: 0.6597 - acc: 0.607 - ETA: 0s - loss: 0.6598 - acc: 0.607 - 1s 5us/sample - loss: 0.6600 - acc: 0.6071\n",
      "Train on 157653 samples, validate on 27592 samples\n",
      "Epoch 1/10\n",
      "157653/157653 - 4s - loss: 0.6891 - acc: 0.5369 - val_loss: 0.6824 - val_acc: 0.5756\n",
      "Epoch 2/10\n",
      "157653/157653 - 3s - loss: 0.6861 - acc: 0.5483 - val_loss: 0.6806 - val_acc: 0.5828\n",
      "Epoch 3/10\n",
      "157653/157653 - 3s - loss: 0.6845 - acc: 0.5521 - val_loss: 0.6768 - val_acc: 0.5809\n",
      "Epoch 4/10\n",
      "157653/157653 - 3s - loss: 0.6838 - acc: 0.5542 - val_loss: 0.6771 - val_acc: 0.5820\n",
      "Epoch 5/10\n",
      "157653/157653 - 3s - loss: 0.6831 - acc: 0.5565 - val_loss: 0.6741 - val_acc: 0.5908\n",
      "Epoch 6/10\n",
      "157653/157653 - 3s - loss: 0.6826 - acc: 0.5568 - val_loss: 0.6748 - val_acc: 0.5839\n",
      "Epoch 7/10\n",
      "157653/157653 - 3s - loss: 0.6820 - acc: 0.5583 - val_loss: 0.6782 - val_acc: 0.5709\n",
      "Epoch 8/10\n",
      "157653/157653 - 3s - loss: 0.6818 - acc: 0.5577 - val_loss: 0.6773 - val_acc: 0.5831\n",
      "Epoch 9/10\n",
      "157653/157653 - 3s - loss: 0.6814 - acc: 0.5583 - val_loss: 0.6777 - val_acc: 0.5826\n",
      "Epoch 10/10\n",
      "157653/157653 - 3s - loss: 0.6809 - acc: 0.5599 - val_loss: 0.6734 - val_acc: 0.5858\n",
      "197067/197067 [==============================] - ETA: 0s - loss: 0.6656 - acc: 0.589 - ETA: 0s - loss: 0.6642 - acc: 0.604 - ETA: 0s - loss: 0.6639 - acc: 0.605 - ETA: 0s - loss: 0.6629 - acc: 0.608 - ETA: 0s - loss: 0.6643 - acc: 0.604 - ETA: 0s - loss: 0.6645 - acc: 0.602 - ETA: 0s - loss: 0.6647 - acc: 0.601 - ETA: 0s - loss: 0.6644 - acc: 0.602 - ETA: 0s - loss: 0.6654 - acc: 0.599 - ETA: 0s - loss: 0.6655 - acc: 0.598 - ETA: 0s - loss: 0.6660 - acc: 0.597 - ETA: 0s - loss: 0.6665 - acc: 0.596 - ETA: 0s - loss: 0.6664 - acc: 0.596 - ETA: 0s - loss: 0.6665 - acc: 0.596 - ETA: 0s - loss: 0.6669 - acc: 0.595 - ETA: 0s - loss: 0.6669 - acc: 0.595 - 1s 5us/sample - loss: 0.6671 - acc: 0.5948\n",
      "Train on 157653 samples, validate on 27592 samples\n",
      "Epoch 1/10\n",
      "157653/157653 - 4s - loss: 0.6918 - acc: 0.5231 - val_loss: 0.6879 - val_acc: 0.5510\n",
      "Epoch 2/10\n",
      "157653/157653 - 4s - loss: 0.6907 - acc: 0.5294 - val_loss: 0.6882 - val_acc: 0.5442\n",
      "Epoch 3/10\n",
      "157653/157653 - 4s - loss: 0.6902 - acc: 0.5320 - val_loss: 0.6869 - val_acc: 0.5376\n",
      "Epoch 4/10\n",
      "157653/157653 - 3s - loss: 0.6899 - acc: 0.5324 - val_loss: 0.6839 - val_acc: 0.5520\n",
      "Epoch 5/10\n",
      "157653/157653 - 3s - loss: 0.6897 - acc: 0.5331 - val_loss: 0.6829 - val_acc: 0.5540\n",
      "Epoch 6/10\n",
      "157653/157653 - 4s - loss: 0.6893 - acc: 0.5352 - val_loss: 0.6841 - val_acc: 0.5399\n",
      "Epoch 7/10\n",
      "157653/157653 - 3s - loss: 0.6892 - acc: 0.5352 - val_loss: 0.6825 - val_acc: 0.5588\n",
      "Epoch 8/10\n",
      "157653/157653 - 3s - loss: 0.6889 - acc: 0.5362 - val_loss: 0.6783 - val_acc: 0.5756\n",
      "Epoch 9/10\n",
      "157653/157653 - 4s - loss: 0.6888 - acc: 0.5359 - val_loss: 0.6834 - val_acc: 0.5591\n",
      "Epoch 10/10\n",
      "157653/157653 - 3s - loss: 0.6884 - acc: 0.5370 - val_loss: 0.6823 - val_acc: 0.5661\n",
      "197067/197067 [==============================] - ETA: 0s - loss: 0.6778 - acc: 0.582 - ETA: 0s - loss: 0.6787 - acc: 0.582 - ETA: 0s - loss: 0.6779 - acc: 0.584 - ETA: 0s - loss: 0.6777 - acc: 0.583 - ETA: 0s - loss: 0.6778 - acc: 0.583 - ETA: 0s - loss: 0.6779 - acc: 0.583 - ETA: 0s - loss: 0.6779 - acc: 0.584 - ETA: 0s - loss: 0.6774 - acc: 0.585 - ETA: 0s - loss: 0.6780 - acc: 0.582 - ETA: 0s - loss: 0.6777 - acc: 0.583 - ETA: 0s - loss: 0.6777 - acc: 0.583 - ETA: 0s - loss: 0.6778 - acc: 0.583 - ETA: 0s - loss: 0.6774 - acc: 0.583 - ETA: 0s - loss: 0.6775 - acc: 0.582 - ETA: 0s - loss: 0.6778 - acc: 0.581 - ETA: 0s - loss: 0.6778 - acc: 0.581 - 1s 5us/sample - loss: 0.6780 - acc: 0.5818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier.get_dependent_variable()\n",
    "classifier.CNN_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       0.59      0.57      0.58     13509\n",
      "          up       0.60      0.61      0.61     14083\n",
      "\n",
      "    accuracy                           0.59     27592\n",
      "   macro avg       0.59      0.59      0.59     27592\n",
      "weighted avg       0.59      0.59      0.59     27592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classifier.Evaluation(target='validation')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save_CNN('D:\\\\庫存健診開發\\\\code\\\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       0.62      0.64      0.63      4994\n",
      "          up       0.70      0.68      0.69      6251\n",
      "\n",
      "    accuracy                           0.66     11245\n",
      "   macro avg       0.66      0.66      0.66     11245\n",
      "weighted avg       0.66      0.66      0.66     11245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-37cbfb8d7502>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_X_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "m = model.copy()\n",
    "m.fit(classifier._X_train, classifier._y_train, validation_data=(classifier._X_val, classifier._y_val), batch_size=256, epochs=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.6, 0. , 0.6, 0.6, 0. ]),\n",
       " array([0. , 0.4, 0. , 0. , 0.4]),\n",
       " array([0.2, 0.2, 0. , 0. , 0. ])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.array([[1,0, 1,1,0], [0,1,0,0,1], [1,1,0,0,0]])\n",
    "a = np.array([0.6, 0.4, 0.2])\n",
    "[item * rate for item, rate in zip(s,a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.5       , 0.5       , 0.5       , 0.33333333])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([item * rate for item, rate in zip(s,a)]) / sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3, 4, 5]),\n",
       " array([ 2,  4,  6,  8, 10]),\n",
       " array([ 3,  6,  9, 12, 15])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item * rate for item, rate in zip(s,a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
