{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# tqdm.pandas()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, TimeDistributed, LeakyReLU, Conv1D, BatchNormalization, MaxPooling1D, AveragePooling1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "\n",
    "import pickle\n",
    "import Model_function as func\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 0\n",
    "with open(f'D:\\\\庫存健診開發\\\\data\\\\Training\\\\processed\\\\Cluster_{cluster}_classification_minmax0_Weekly', 'rb') as fp:\n",
    "    load_list = pickle.load(fp)\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load_list[0], load_list[1], load_list[2], load_list[3]\n",
    "X_train, Y_train, X_val, Y_val = func.validation_split(X_train, Y_train)\n",
    "y_train, y_val, y_test = func.get_dependent_variable(Y_train, Y_val, Y_test)\n",
    "y_train_encode, y_val_encode, y_test_encode = func.categorical_transform(y_train), func.categorical_transform(y_val), func.categorical_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Tree_Classifier():\n",
    "    def __init__(self, train, val, test, classifier):\n",
    "        self.X_train = np.array(train[0])\n",
    "        self.Y_train = np.array(train[1])\n",
    "        self.X_val = np.array(val[0])\n",
    "        self.Y_val = np.array(val[1])\n",
    "        self.X_test = np.array(test[0])\n",
    "        self.Y_test = np.array(test[1])\n",
    "        self.classifier = classifier.lower()\n",
    "        self.param1 = {}\n",
    "        self.param2 = {}\n",
    "\n",
    "        \n",
    "    def CNN_param(self, param):\n",
    "        self.param1 = param\n",
    "    \n",
    "    def CNN(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(\n",
    "                filters=self.param1['l1_filter'], \n",
    "                kernel_size=self.param1['l1_kernel'], \n",
    "                activation='relu', \n",
    "                input_shape=(self.X_train.shape[1], self.X_train.shape[2]), \n",
    "                padding=self.param1['padding1']))\n",
    "        \n",
    "        model.add(Conv1D(\n",
    "                filters=self.param1['l2_filter'], \n",
    "                kernel_size=self.param1['l2_kernel'], \n",
    "                activation='relu',\n",
    "                padding=self.param1['padding2']))\n",
    "            \n",
    "        if (self.param1['dropout']) and (self.param1['Conv_layer'] <= 2):\n",
    "            model.add(Dropout(self.param1['dropout_ratio']))\n",
    "        \n",
    "        if self.param1['Conv_layer'] > 2:\n",
    "            model.add(Conv1D(\n",
    "                filters=self.param1['l3_filter'], \n",
    "                kernel_size=self.param1['l3_kernel'], \n",
    "                activation='relu',\n",
    "                padding=self.param1['padding3']))\n",
    "            if self.param1['dropout']:\n",
    "                model.add(Dropout(self.param1['dropout_ratio']))\n",
    "                \n",
    "        model.add(Flatten(name='feature'))\n",
    "        \n",
    "        if self.param1['Dense']:\n",
    "            model.add(Dense(self.param1['Dense']))\n",
    "            model.add(Dropout(self.param1['dropout_ratio']))\n",
    "            \n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizers.Nadam(lr=0.001), metrics=[tf.keras.metrics.AUC()])\n",
    "        self.CNN_ = model.fit(self.X_train, self.Y_train, validation_data=(self.X_val, self.Y_val), batch_size=self.param1['batchsize'], epochs=self.param1['epochs'], verbose=2)\n",
    "        \n",
    "    def Feature_extraction(self):\n",
    "        intermediate_layer_model = Model(inputs=self.CNN_.input, outputs=self.CNN_.get_layer('feature').output)\n",
    "        self.training_feature_ = intermediate_layer_model.predict(self.X_train)\n",
    "        self.val_feature_ = intermediate_layer_model.predict(self.X_val)\n",
    "        self.testing_feature_ = intermediate_layer_model.predict(self.X_test)\n",
    "        \n",
    "    def Classifier_param(self, param):\n",
    "        self.param2 = param\n",
    "        \n",
    "    def Classifier(self):\n",
    "        if self.classifier == 'randomforest':\n",
    "            classifier = RandomForestClassifier(n_estimators = 400, max_depth=20, verbose=1, n_jobs=-1)\n",
    "            self.model_ = forest.fit(self.training_feature_, self.y_train)\n",
    "        elif self.classifier == 'xgboost':\n",
    "            classifier = XGBClassifier()\n",
    "            self.model_ = classifier.fit(self.training_feature_, self.y_train, eval_set = [(self.training_feature_, self.y_train), (self.val_feature_, self.y_train)], verbose=True, eval_metric='auc')\n",
    "\n",
    "        else:\n",
    "            return 'Classifier not exist'\n",
    "        \n",
    "    \n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
